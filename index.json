[{"content":"","date":"19 November 2024","externalUrl":null,"permalink":"/develop/","section":"Develops","summary":"","title":"Develops","type":"develop"},{"content":"","date":"19 November 2024","externalUrl":null,"permalink":"/","section":"鲸云🐳","summary":"","title":"鲸云🐳","type":"page"},{"content":"","date":"7 November 2024","externalUrl":null,"permalink":"/tags/docker/","section":"Tags","summary":"","title":"Docker","type":"tags"},{"content":"","date":"7 November 2024","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"},{"content":"","date":"7 November 2024","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":" 安装必要的依赖包： sudo yum install -y yum-utils device-mapper-persistent-data lvm2 设置 Docker 的阿里云 Yum 仓库： sudo yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 列出可用的 Docker 版本： yum list docker-ce --showduplicates | sort -r 安装指定版本： sudo yum install -y docker-ce-20.10.13 docker-ce-cli-20.10.13 containerd.io 启动并设置开机自启动： sudo systemctl start docker sudo systemctl enable docker 验证安装： sudo docker --version sudo docker run hello-world ","date":"7 November 2024","externalUrl":null,"permalink":"/develop/container/%E5%AE%89%E8%A3%85%E6%8C%87%E5%AE%9A%E7%89%88%E6%9C%AC%E7%9A%84docker%E5%B9%B6%E8%AE%BE%E7%BD%AE%E9%98%BF%E9%87%8C%E4%BA%91%E9%95%9C%E5%83%8F/","section":"Develops","summary":"","title":"安装指定版本的docker并设置阿里云镜像","type":"develop"},{"content":"","date":"7 November 2024","externalUrl":null,"permalink":"/series/%E5%BC%80%E5%8F%91/","section":"Series","summary":"","title":"开发","type":"series"},{"content":"","date":"30 October 2024","externalUrl":null,"permalink":"/tags/ssh/","section":"Tags","summary":"","title":"Ssh","type":"tags"},{"content":" 生成ssh密钥并通过ssh密钥连接远程服务器 # 生成 SSH 密钥对： 在本地终端运行以下命令生成 SSH 密钥对：\nssh-keygen -t rsa -b 4096 -C \u0026#34;your_email@example.com\u0026#34; 按照提示输入保存密钥的文件路径（默认是 ~/.ssh/id_rsa）和密码（可选）。\n将公钥添加到远程服务器： 使用以下命令将公钥（默认为 ~/.ssh/id_rsa.pub）添加到远程服务器的 ~/.ssh/authorized_keys 文件中：\nssh-copy-id -i ~/.ssh/id_rsa.pub remote_user@remote_host 按照提示输入远程服务器的密码。完成后，你的公钥将被添加到远程服务器的 `~/.ssh/authorized\n","date":"30 October 2024","externalUrl":null,"permalink":"/develop/record/%E7%94%9F%E6%88%90ssh%E5%AF%86%E9%92%A5%E5%B9%B6%E9%80%9A%E8%BF%87ssh%E5%AF%86%E9%92%A5%E8%BF%9E%E6%8E%A5%E8%BF%9C%E7%A8%8B%E6%9C%8D%E5%8A%A1%E5%99%A8/","section":"Develops","summary":"","title":"生成ssh密钥并通过ssh密钥连接远程服务器","type":"develop"},{"content":"","date":"30 October 2024","externalUrl":null,"permalink":"/tags/%E8%BF%90%E7%BB%B4/","section":"Tags","summary":"","title":"运维","type":"tags"},{"content":"","date":"24 October 2024","externalUrl":null,"permalink":"/tags/nginx/","section":"Tags","summary":"","title":"Nginx","type":"tags"},{"content":" 问题背景 # 新项目需要用到websocket进行通讯,有一个问题就是脚手架提供的websocket通讯是走ws协议的也就是http,因此需要用nginx来转发https请求。 ps: 我们用的spring-websocket好像websocket可以支持配置一些证书的信息,没办法着急提测太懒了，回头再研究下补上。\nnginx配置 # 没啥好说的,固定路径转发到http请求,直接上配置\nlocation /wss-xg { proxy_pass http://ip:port/xg-security/resource/websocket?$args; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade;##此处Upgrade注意大小写 proxy_set_header Connection \u0026#34;Upgrade\u0026#34;; proxy_set_header Remote_addr $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_read_timeout 600s; } 额外补充 # js好像在websocket请求中，token是没法通过header去传递的(没验证,其他博客里看到的)，所有如果需要权限验证，可以在requestParam里传 如果前端使用了socket.io这类框架来做socket请求处理，那么有可能会对后端的socket路径有要求。 例如对于我们这个项目，前端在调试时使用的是https://address/wss-xg,但是实际请求就是wss://address/socket.io?xxx,本来应该统一对该请求 做代理但是由于已经有了其他项目用这种方式接入了websocket所以我这里也没法用了,这里附下socket.io方式的nginx配置 location ^~/socket.io/ { proxy_pass http://test.jinyingweishi.cn:28889; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade;##此处Upgrade注意大小写 proxy_set_header Connection \u0026#34;Upgrade\u0026#34;; proxy_set_header Remote_addr $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_connect_timeout 15s; proxy_send_timeout 3600s; proxy_read_timeout 3600s; } ","date":"24 October 2024","externalUrl":null,"permalink":"/develop/middleware/nginx/nginx%E8%B5%B0https%E8%BD%AC%E5%8F%91websocket%E8%AF%B7%E6%B1%82/","section":"Develops","summary":"","title":"Nginx走https转发websocket请求","type":"develop"},{"content":"","date":"24 October 2024","externalUrl":null,"permalink":"/tags/websocket/","section":"Tags","summary":"","title":"Websocket","type":"tags"},{"content":" 问题背景 # 在项目开发中有时候我们会遇到一条记录中可能某条记录的某个属性对应多个值的问题，\n一般情况下我们是采用 “,” 拼接然后以字符串的形式存储的方案。这种方案有一个不好的地方就是需要在代码中硬编码。 因此为了解决这个问题我基于数据库varchar类型 + mybatisPlus的filedHandler + TableFiled注解 做了个小方案来解决它, 使用的话只需要在List属性上使用注解即可。 整体设计 # 首先我们要保证在整体java项目中除了实体类要添加注解之外，在业务代码中无感，所以要考虑在接收请求，和数据入库两个点有没有有问题。 接收请求可以由web框架自动序列化，我们只需要定义List类型的属性即刻 public class SysDept { private List\u0026lt;Integer\u0026gt; deptType; } 其次在入库时数据库要实现List存储，现有的数据结构已经无法满足，所以肯定是varchar类型，因为我们只需要使用自定义Handler并配合注解来处理序列化和反序列化时的数据解析即可。 @TableName(value = \u0026#34;sys_dept\u0026#34;,autoResultMap = true) public class SysDept { @TableField(typeHandler = MpListHandler.class) private List\u0026lt;Integer\u0026gt; deptType; } 源码 # // 数据处理器 @MappedTypes({List.class}) @MappedJdbcTypes(JdbcType.VARCHAR) public class MpListHandler extends JacksonTypeHandler { public static final String QUERY_SPLIT = \u0026#34;,\u0026#34;; @Override protected Object parse(String json) { json = RegExUtils.replaceAll(json, Pattern.quote(\u0026#34;[,\u0026#34;), \u0026#34;[\u0026#34;); json = RegExUtils.replaceAll(json, Pattern.quote(\u0026#34;,]\u0026#34;), \u0026#34;]\u0026#34;); return super.parse(json); } @Override protected String toJson(Object obj) { String json = super.toJson(obj); json = RegExUtils.replaceAll(json, Pattern.quote(\u0026#34;[\u0026#34;), \u0026#34;[,\u0026#34;); json = RegExUtils.replaceAll(json, Pattern.quote(\u0026#34;]\u0026#34;), \u0026#34;,]\u0026#34;); return json; } public MpListHandler() { super(List.class); } public static String queryValue(Object param) { return QUERY_SPLIT + param + QUERY_SPLIT; } /** * list in 条件查询 * * @param lqw * @param deptType */ public static void listInQuery(LambdaQueryWrapper\u0026lt;SysDept\u0026gt; lqw, List\u0026lt;?\u0026gt; deptType) { if (CollUtil.isNotEmpty(deptType)) { lqw.and(t-\u0026gt;{ for (Object value : deptType) { t.or().like(SysDept::getDeptType, MpListHandler.queryValue(value)); } }); } } } 坑点 # 实体类上注解 @TableName(value = \u0026ldquo;sys_dept\u0026rdquo;,autoResultMap = true) 的autoResultMap一定要开启 针对于该属性的in匹配需要考虑下，源码中给出了一个方法是拆除每个item，用like和or来匹配 ","date":"16 October 2024","externalUrl":null,"permalink":"/develop/design/java%E9%A1%B9%E7%9B%AE%E4%B8%AD%E7%9A%84list%E7%B1%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E8%AE%BE%E8%AE%A1/","section":"Develops","summary":"","title":"java项目中的List类型数据存储设计","type":"develop"},{"content":"","date":"16 October 2024","externalUrl":null,"permalink":"/tags/mybatis/","section":"Tags","summary":"","title":"Mybatis","type":"tags"},{"content":"","date":"16 October 2024","externalUrl":null,"permalink":"/tags/%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%A1%88/","section":"Tags","summary":"","title":"设计方案","type":"tags"},{"content":"","date":"15 October 2024","externalUrl":null,"permalink":"/tags/mysql/","section":"Tags","summary":"","title":"Mysql","type":"tags"},{"content":" 问题描述 # 今天排查一个问题,sql语句查询不到数据，明明有数据却查不出任务数据sql类似于\nselect * for XXX where XX != null; 正确的语句是\nselect * for XXX where XX is not null; 原因 # 在 MySQL 中，NULL 用于表示缺失的或未知的数据，处理 NULL 值需要特别小心，因为在数据库中它可能会导致不同于预期的结果。\n为了处理这种情况，MySQL提供了三大运算符:\nIS NULL: 当列的值是 NULL,此运算符返回 true。 IS NOT NULL: 当列的值不为 NULL, 运算符返回 true。 \u0026lt;=\u0026gt;: 比较操作符（不同于 = 运算符），当比较的的两个值相等或者都为 NULL 时返回 true 关于 NULL 的条件比较运算是比较特殊的。你不能使用 = NULL 或 != NULL 在列中查找 NULL 值 。\n在 MySQL 中，NULL 值与任何其它值的比较（即使是 NULL）永远返回 NULL，即 NULL = NULL 返回 NULL 。\n可能涉及的null值处理 # 检查是否为 NULL 要检查某列是否为 NULL，可以使用 IS NULL 或 IS NOT NULL 条件。 SELECT * FROM employees WHERE department_id IS NULL; 使用 COALESCE 函数处理 NULL COALESCE 函数可以用于替换为 NULL 的值，它接受多个参数，返回参数列表中的第一个非 NULL 值： SELECT product_name, COALESCE(stock_quantity, 0) AS actual_quantity FROM products; 使用 IFNULL 函数处理 NULL IFNULL 函数是 COALESCE 的 MySQL 特定版本，它接受两个参数，如果第一个参数为 NULL，则返回第二个参数。 SELECT product_name, IFNULL(stock_quantity, 0) AS actual_quantity FROM products; 使用 \u0026lt;=\u0026gt; 操作符进行 NULL 比较 \u0026lt;=\u0026gt; 操作符是 MySQL 中用于比较两个表达式是否相等的特殊操作符，对于 NULL 值的比较也会返回 TRUE。它可以用于处理 NULL 值的等值比较。 SELECT * FROM employees WHERE commission \u0026lt;=\u0026gt; NULL; 注意聚合函数对 NULL 的处理 在使用聚合函数（如 COUNT, SUM, AVG）时，它们会忽略 NULL 值，因此可能会得到不同于预期的结果。如果希望将 NULL 视为 0，可以使用 COALESCE 或 IFNULL。 SELECT AVG(COALESCE(salary, 0)) AS avg_salary FROM employees; ","date":"15 October 2024","externalUrl":null,"permalink":"/develop/record/mysql%E4%B8%ADnull%E6%9F%A5%E8%AF%A2%E4%B8%8D%E5%87%BA%E6%9D%A5%E6%95%B0%E6%8D%AE/","section":"Develops","summary":"","title":"Mysql中!=null查询不出来数据","type":"develop"},{"content":" MQTT协议入门 # 参考文档维基百科、阿里云消息队列MQTT版本、MQTT3.1.1协议\n协议来源 # mqtt协议最早在1999年被撰写。最初的目的是为了监控石油管道石油运输,所以需要一个轻量高效，占用带宽和电量少的协议。 因为那个时候类似于这种设备只能通过卫星去进行数据通讯，开销很大。\n协议组成 # mqtt协议定义了两种网络实体,broker和clients（一个消息broker和多个clients）。\nbroker的主要作用是接收client发送来的消息，并通过路由转发给目标client，消息的发送方和接收方都完全不需要感知到目标client的地址 或者存储任何路由表。\nclient是用来收发消息的客户端，它可以是任何设备，只要装载了mqtt库并且连接到了broker那么他就可以作为client来进行收发消息\n消息流转 # client会发送 控制消息(control message) 由message + topic组成 到 broker，控制消息最小2字节，最大可以256mb broker会根据订阅信息，向所有订阅了topic的client转发消息 如果没有client订阅该消息，那么该消息会被丢弃掉，除非设置了保留消息 broker会保留最近的一条保留数据，当用client订阅topic的时候会立即推送 broker # broker可以部署在本地或者云上,它会维护一个由层级结构的topic，当client发送消息到某个topic后， 所有订阅了该topic的client都会收到一个该消息副本。\n之所以说是层级结构的是因为topic可以用‘/’来区分层级，使用‘+’可以匹配单个层级，使用‘#’可以匹配多个层级\nhome/#可以匹配 home/living_room/temperature、home/bedroom/temperature\nhome/+/temperature 可以匹配 home/living_room/temperature 和 home/bedroom/temperature。\n消息类型 # connect # 表示等待与服务建立一个明确的连接,希望和服务建立一个连接\ndisconnect # 等待 MQTT 客户端完成其必须执行的所有工作，并等待 TCP/IP 会话断开连接\npublish # 将请求传递给 MQTT 客户端后立即返回到应用程序线程。\nQuality of service(QOS) # QoS 0 最多一次 – 消息仅发送一次，客户端和代理无需采取任何额外步骤来确认发送（即发即忘）。 QoS 1 至少一次 – 发送者多次重试消息，直到收到确认（确认发送）。 Qos 2 恰好一次——发送者和接收者进行两级握手，以确保只接收到消息的一份副本（保证传递）。 阿里云云消息队列MQTT # ","date":"14 September 2024","externalUrl":null,"permalink":"/develop/network/mqtt%E5%8D%8F%E8%AE%AE/","section":"Develops","summary":"","title":"MQTT协议","type":"develop"},{"content":" TCP_IP协议族 # 文章总结自 TCP、UDP、HTTP、SOCKET、WebSocket之间的区别 TCP/IP 四层模型概述\n协议模型 # OSI七层模型 # 各层作用 # 应用层：负责提供各种软件的运行环境，运行在操作系统用户态\n表示层：负责将不同设备间传输的数据转换为彼此可以理解的格式\n会话层：负责表示层实体之间会话的建立，管理和终止\n传输层：负责建立不同设备之间端到端的连接\n网络层：负责根据目的 IP 地址实现寻址及路由选择\n数据链路层：负责数据包封帧及 MAC 寻址\n物理层：负责数据帧在物理网络中的实际传输\nTCP/IP四层模型 # 四层模型 # 各层协议 # 这里拿发一次快递作为举例\nPDU 协议数据单元\n应用层PDU 数据 传输层PDU 数据段 网络层PDU 数据包 物理层PDU 比特(位)\n应用层 # 应用层可以类比于我们寄快递时候的货物,货物需要进行打包，并且贴上收件人，收件地址等，这才成为一个可以运输的快递\n应用层协议主要作用时将我们所需要传输的数据按照一定的数据形式和传输规则，将数据封装。\n运作在应用层上的协议有HTTPS/HTTP、FTP、DNS、DHCP、SMTP等\n传输层 # 应用层可以类比于我们寄快递时候的快递站,快递站不负责实际的运输,他只会将快递分着快递公司分开然后发到不同的快递中转站，\n传输层同样也并不涉及实际传输，主要作用是端口对端口的通信，运作在其上的协议主要是TCP/UPD。\ntcp协议 TCP协议通过了三次握手，四次挥手，慢启动，拥塞避免，超时重试等机制保障了数据的可靠传输，但是效率低。 TCP协议规定当报文长度超过MSS（Max Segement Size：最大报文长度）后，需要对数据报文进行分段， 然后组成TCP报文段交给网络层进行传输. 之所以在传输层将消息切片是为了更高效的解决网络层丢包的问题。如果我们不切，那么会在应用层按照MTU（Max Transport Unit：最大传输单元)来进行切片，这样 的话一旦丢包需要将整个数据来进行重发效率低下，所以在传输层就将数据切片，哪个包丢了重发就好。 tcp协议存在粘包问题，粘包的问题可以细分为 发送端粘包 和 接收端粘包 发送端粘包： 1.tcp内部默认开启nagle算法，该算法会将较小的报文进行合并发送，这是导致粘包的原因，可以通过关闭nagle算法解决 2.TCP连接的发送方会将报文段放在缓冲区，等缓冲区装满之后再发送，这也会导致粘包 接收方粘包 1.TCP连接的接收方未即使取走到达缓冲区的报文段 针对于发送端和接收端缓冲区未即使处理粘包可以采用如下策略: 1.应用层定义消息头部,http协议就是将消息划分为头部和数据部分 2.固定消息长度，所有消息固定长度，接收方直接按照指定长度切割，无需考虑粘包 udp协议 UDP协议面向无连接，只管发送，至于是否交付到接收方不作保证，所以效率高，可靠性低。 网络层 # 网络层类比于快递中转站，他们负责将全市的站点送来的包裹进行收集，按照地址进行分拣，并装车。\n网络层收到数据传输层的数据之后，会按照MTU来进行数据切片，然后再头部添加IP包头，组成数据包。然后再通过IP协议寻址\n寻址过程 Ip由网络号 + 主机号组成,寻址时会先用 ip 和子网掩码进行 与运算 然后再自身的路由表中寻找结果与该结果相同的路由器表项（说明网络号相同,同属于一个子网），发送给路由器。 如果没找到就回吧报文发送给默认网关，网关会重复之前的操作，直到找到目标低至所在子网，最后广播目标IP地址。 如果某个阶段没有找到合适的路由，则会产生 ICMP 报错数据包 如果是直连路由（即同一个子网内）则按照第二层 MAC 地址直接发送数据\n网络接口层 # 网络接口层类比于快递车运输，负责实际的运输。\n通过ip寻址和路由器选择我们知道了要发送数据去哪，但是ip仅仅可以确定我们要发到那个子网，子网内部的设备之间的数据传输就需要依靠mac地址来解决了。\nmac寻址过程 每个入网的网卡本身会写在一个48位的mac地址，是生产时候就被写入到rom中的，自身的mac地址都可以通过rom获取 下个节点的mac地址可以通过地址转换协议ARP获取 源主机会广播 FF:FF:FF:FF:FF:FF + 目的主机 IP 地址 给子网内所有的主机 目标机器收到指令后发现ip与自身ip相同，那么就会返回给请求方，请求方获取下个mac地址后，会将这对地址缓存到ARP缓存空间中，下次查询就有可能命中，一般只存几分钟 ","date":"14 September 2024","externalUrl":null,"permalink":"/develop/network/tcp_ip%E6%A8%A1%E5%9E%8B/","section":"Develops","summary":"","title":"TCP_IP模型","type":"develop"},{"content":"","date":"14 September 2024","externalUrl":null,"permalink":"/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/","section":"Tags","summary":"","title":"网络编程","type":"tags"},{"content":"","date":"14 September 2024","externalUrl":null,"permalink":"/tags/java/","section":"Tags","summary":"","title":"Java","type":"tags"},{"content":" 定义 # lambda表达式允许我们把函数当作一个方法的入参传入\n是java中的一个重要特性。\n结构 # （parameters）-\u0026gt; expression;\n（parameters）-\u0026gt; {statements};\n函数式接口 # 只声明了一个抽象函数的接口就是函数式接口，我们可以使用@FunctionInterface来保证该接口是一个函数式接口。\n我们使用lambda表达式实际上就是生成一个函数式接口的对象。\njava内置的函数式接口 # 方法引用 # 方法引用可以理解为lambda表达式的另一种表现形式。当函数式接口所需要用的对应的方法已经有了实现时可以使用方法引用。\nFunction\u0026lt;Integer, Integer\u0026gt; square = Math::square; int result = square.apply(4); // 结果为 16 Function\u0026lt;String, Integer\u0026gt; strLength = String::length; int result = strLength.apply(\u0026#34;Hello\u0026#34;); // 结果为 5 Function\u0026lt;String, Person\u0026gt; createPerson = Person::new; Person person = createPerson.apply(\u0026#34;Alice\u0026#34;); ","date":"14 September 2024","externalUrl":null,"permalink":"/develop/language/java/java%E4%B8%AD%E7%9A%84lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F%E4%B8%8E%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B/","section":"Develops","summary":"","title":"java中的lambda表达式与函数式编程","type":"develop"},{"content":"","date":"14 September 2024","externalUrl":null,"permalink":"/tags/canal/","section":"Tags","summary":"","title":"Canal","type":"tags"},{"content":" 测试背景 # 本次测试在本地,用3个库做同步测试,由canal_master_1和canal_master_2往canal_sync同步数据 文件配置 # canal的配置会涉及到文件夹、配置文件、配置文件之间的关联,总的逻辑关系如下 deployer配置 # deployer的主要作用是对数据库进行监听,伪装destination的从库，解析其binlog\ncanal/conf/canal.properties 是deployer主配置我们主要关注destinations下的配置\n################################################# ######### destinations\t############# ################################################# # master1和master2对应着conf下的两个文件夹，其中存放着具体的监听库信息、库表过滤规则等 canal.destinations = master1,master2 ps:多余配置已经裁剪,只关注主要修改配置\nmaster1(2)文件夹配置 # master1(2)文件夹就对应着destinations中的配置项，其含义是被监听的数据源，该文件夹下存放其相关配置在instance.properties\n# username/password canal.instance.master.address=127.0.0.1:3306 canal.instance.dbUsername=root canal.instance.dbPassword=12345678 canal.instance.connectionCharset = UTF-8 # 默认监听源数据库 canal.instance.defaultDatabaseName=canal_master_1 canal.instance.enableDruid=false # table regex canal.instance.filter.regex=canal_master_1.order,canal_master_1.order_item adapter配置 # adapter端的作用是解析来自deployer端的binlog数据并适配转储到各种数据库本次案例中是从mysql适配到mysql.\nadapter的主配置在conf/application.yml\nouterAdapters代表着外部适配器配置，也就是conf配置下单独拎出来文件夹存放配置的意思\nname 代表文件夹名称，这里mysql使用的是rdb key 是代表具体配置名称，该配置主要是配置映射规则 properties 其下配置的是需要同步到的数据库，及目标库这里目标库只有一个canal_sync所以保持一致即可 server: port: 8081 spring: jackson: date-format: yyyy-MM-dd HH:mm:ss time-zone: GMT+8 default-property-inclusion: non_null canal.conf: mode: tcp #tcp kafka rocketMQ rabbitMQ flatMessage: true zookeeperHosts: syncBatchSize: 1000 retries: -1 timeout: accessKey: secretKey: consumerProperties: # canal tcp consumer canal.tcp.server.host: 127.0.0.1:11111 canal.tcp.batch.size: 500 srcDataSources: defaultDS: url: jdbc:mysql://127.0.0.1:3306/canal_master_1 username: root password: 12345678 canalAdapters: - instance: master1 # canal instance Name or mq topic name groups: - groupId: g1 outerAdapters: - name: rdb key: master1Mapping properties: jdbc.driverClassName: com.mysql.jdbc.Driver jdbc.url: jdbc:mysql://127.0.0.1:3306/canal_sync jdbc.username: root jdbc.password: 12345678 druid.stat.enable: false druid.stat.slowSqlMillis: 1000 - instance: master2 # canal instance Name or mq topic name groups: - groupId: g1 outerAdapters: - name: rdb key: master2Mapping properties: jdbc.driverClassName: com.mysql.jdbc.Driver jdbc.url: jdbc:mysql://127.0.0.1:3306/canal_sync jdbc.username: root jdbc.password: 12345678 druid.stat.enable: false druid.stat.slowSqlMillis: 1000 outerAdapters # 配置master1Mapping.yml时可以用dataSourceKey 关联数据源，也可以使用destination来关联数据源\n#dataSourceKey: defaultDS destination: master1 groupId: g1 outerAdapterKey: master1Mapping concurrent: true dbMapping: database: canal_master_1 table: order targetTable: order targetPk: id: id tenant_id: tenant_id mapAll: true commitBatch: 3000 # 批量提交的大小 至此配置已经完成，接下来我将针对给出的配置给到具体的测试数据\n测试报告 # 双库插入,同步库同步情况 # 测试案例: master1 和 master2 各自写入一条数据观察 canal_sync库数据情况 测试结果: 我们可以通过日志观测到数据已经被adapter解析并执行同步 插入结果 验证destination 和 dataSourceKey # 测试案例: 注释掉master1Mapping 和 master2Mapping 中的destination，启动后做数据同步\n测试结果: 数据同步均失败\n原因分析: 默认情况下adapter会从deployer中拉取binlog，并转换成目标格式。但是在某些情况下可能需要进行回查等操作，就需要用到 dataSourceKey中的配置信息\n至此此次测试案例结束\n参考链接: srcDataSources的作用是什么\n","date":"14 September 2024","externalUrl":null,"permalink":"/develop/middleware/canal/canal%E5%A4%9A%E5%AF%B9%E4%B8%80%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E6%B5%8B%E8%AF%95%E6%A1%88%E4%BE%8B/","section":"Develops","summary":"","title":"Canal多对一数据同步测试案例","type":"develop"},{"content":" 业务背景 # 我们有这样的一个场景，一个主系统和N个子系统，子系统之间数据隔离,主系统有全部数据。\n于是针对数据同步就有了两个需求点\n需要可以在将N个子系统的数据实时同步到主系统 需要考虑主子系统之间出现网路隔离子系统仍然正常工作可操作,再网络恢复后主子系统之间进行数据的增量同步。 在这样的背景下我们准备对阿里的cannel和dataX两个工具进行调研\n前置条件 # 目前canal 支持源端 MySQL 版本包括 5.1.x , 5.5.x , 5.6.x , 5.7.x , 8.0.x mysql需要开启binglog # binlog查询命令 show variables like \u0026#39;log_bin\u0026#39;; # mysql开启binlog [mysqld] # 打开binlog log-bin=mysql-bin # 选择ROW(行)模式 binlog-format=ROW # 配置MySQL replaction需要定义，不要和canal的slaveId重复 server_id=1 # 要监控的数据库名称 binlog-do-db=my-test canal原理 # canal的工作原理可以是基于主从同步,但是与主从同步不完全相同。\ncanal是通过伪装成从库通过dump协议从mysql拉取binlog日志，解析binlog日志并将解析后的数据应用到目标数据库\n主从同步通过dump协议拉取binlog日志后，通过binlog回放来达到数据同步的目的\nps:\n主从同步在断网重连的场景下,如果断网时间过长，在数据一致性这块可能会有问题（binlog位置不一致,relay log 损坏，数据冲突等原因）， 需要依赖三方的工具检查和手动解决。\ncanal针对于断网恢复后的数据一致性问题，给出了持久化binlog同步位置信息的方案（文件或者数据库都可），以保证断网后不存在数据一致性问题 业务场景匹配度 # canal支持多子库往一个主库同步的情况 相对于主从同步下的数据一致性问题，canal本身就给了解决方案，无需再借用第三方工具来处理 ","date":"13 September 2024","externalUrl":null,"permalink":"/develop/middleware/canal/canal%E7%9A%84%E8%B0%83%E7%A0%94/","section":"Develops","summary":"","title":"canal调研","type":"develop"},{"content":" 队列 # 定义 # 队列是一种特殊的线性表,他的特殊性在于将线性表的操作限定为表尾插入，表头删除\n通过这个特殊的限定我们可以达到FIFO(first in first out)的目的\n抽象数据类型 # Queue.java\n队列的数组实现（循环队列） # CircleQueue.java\n队列数据存储的问题 # 虽然我们采用数组来作为数据存储的基本结构，但是由于队列的使用过程中头尾指针是动态的。\n所以我们很容一造成头指针到index = 0 之间的空间浪费 因此我们采用 尾指针 = (尾指针 + 1) % data.length的方式来移动尾指针，让尾指针可以循环起来\n这样就解决了存储空间浪费的问题\n尾指针移动的几个问题， # CircleQueue.java#rearMove\n按照正常情况下，队列临界的问题判断应该如下\n# 队列满 this.font == this.rear # 队列空 this.font == this.rear 我们无法区分队列满 和 队列空，需要引入一个新的变量flag来判断。\n我们这里可以使用空出最后一个存储空间的方式来达到该目的，而不用引入新的状态\nthis.rear = ++this.rear % data.length; if (this.rear == this.front){ throw new RuntimeException(\u0026#34;rear is out of size\u0026#34;); } 队列的链表实现实现 # LinkedQueue.java\n","date":"11 September 2024","externalUrl":null,"permalink":"/develop/structure/queue/","section":"Develops","summary":"","title":"队列","type":"develop"},{"content":"","date":"11 September 2024","externalUrl":null,"permalink":"/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","section":"Tags","summary":"","title":"数据结构","type":"tags"},{"content":" 栈 # 定义 # 栈是一种特殊的线性表,只可以在线性表的底部进行插入和删除操作.\n线性表的头部被称为栈底,底部被成为栈顶,也就是说栈只可以在栈顶进行插入或者删除操作\n插入操作被称为压栈(push) 删除操作被叫做弹栈(pop). 抽象数据类型 # 数据 # AbstractStack\n行为 # IStack\nIShardedStack.java\n栈的种类 # 数组栈和链表栈 # 因为栈是特殊的线性表，所以很自然的就想到存在数组和链表两种实现方式。 个人觉得数组这种方式特别合适，因为我们限定了所有操作都要在栈顶，而链表方式会多一些额外开销。\n共享栈 # 共享栈就是两个栈分享一个数组/节点链表，栈顶由单个栈的时候的数组最大值，变成了两个栈顶\u0026quot;发生碰撞\u0026quot; 栈的应用 # 递归 # 递归的典型运用场景就是斐波那契数列\n斐波那契数列: 前两项数的和 f(0) = 0; f(1) = 1; f(n) = f(n-1) + f(n-2);\n普通的执行方法如果我们要算f(20),那么要从 f(0) f(1) f(2)一步步计算到f(20);\n使用递归的化我们是从f(20)开始分解公式,f(20) = f(19) + f(18);再去调用f(18) 和 f(19) 依次往下自己调用自己。\n在这个依次向下的调用过程我们就需要 \u0026ldquo;先将上层的公式存起来\u0026rdquo; 先存起来的公式后算,这和栈结构不谋而合，而在java中执行方法的压栈和出栈也确实是这样的。\n四则运算法则 # 我们常见的表达式 9+（3－1）×3+10÷2 叫做中缀表达式，我们可以很轻松的依据优先级 “ 括号 大于 乘除 大于 加减” 来算出结果\n但是计算机在处理中缀表达式的时候就很难办,于是 波兰的一位逻辑学家 想出来了一个后缀(逆波兰)表达式, 而上述中缀表达式转换后未 9 3 1 - 3 * + 10 2 / +\n中缀表达式转后缀表达式 # 中缀表达式提取后缀表达的基本步骤:\n依次读取表达式中的每一项 符号和数字 ，读取到数字则放到后缀表达式中，读取到符号则放入计算符号栈中 如果栈顶 无符号 或者 优先级小于 当前要放入的符号,则直接放入 如果放入的符号 优先级大于当前符号则取出栈中的所有符号加入表达式 再放入符号 如果放入的符号是) 则取出符号直到(为止 加入表达式 然后再放入符号 后缀表达式的计算逻辑 # 依次将每个表达式的元素放入到计算栈中 如果获取到计算符号则从栈中取出两个数进行计算，之后再放入到栈中 最后计算结束取出栈中数据即可 ","date":"11 September 2024","externalUrl":null,"permalink":"/develop/structure/stack/","section":"Develops","summary":"","title":"栈","type":"develop"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","externalUrl":null,"permalink":"/tags/https/","section":"Tags","summary":"","title":"Https","type":"tags"},{"content":"","externalUrl":null,"permalink":"/menu/","section":"Menus","summary":"","title":"Menus","type":"menu"},{"content":"Nginx或Tengine服务器配置SSL证书_数字证书管理服务（原SSL证书）(SSL Certificate)-阿里云帮助中心\nserver { listen 443 ssl; # 需要注意下最好指定某个域名或者通配 server_name *.{domain}; ssl_certificate /etc/nginx/ssl/default.crt; ssl_certificate_key /etc/nginx/ssl/default.key; } ","externalUrl":null,"permalink":"/develop/middleware/nginx/nginx%E9%85%8D%E7%BD%AEhttps%E8%AF%81%E4%B9%A6/","section":"Develops","summary":"","title":"nginx配置https证书","type":"develop"},{"content":" nginx配置代理转发流量 # 业务背景 # 跟高德平台用808协议调了一个车载摄像头直播，但是高德平台提供的时http协议通讯，我们需求https因此用nginx做一个转发\n错误配置 # server { listen 443 ssl default_server; server_name test.jinyingweishi.cn; ssl_certificate /usr/local/ssl/cert.pem; ssl_certificate_key /usr/local/ssl/cert.key; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; ssl_prefer_server_ciphers on; location / { add_header Access-Control-Allow-Origin *; add_header Access-Control-Allow-Methods \u0026#39;GET, POST, OPTIONS\u0026#39;; add_header Access-Control-Allow-Headers \u0026#39;DNT,X-Mx-ReqToken,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization\u0026#39;; gzip_static on; root /opt/platform/web/supervise; index index.html index.htm; } location /gaodeX { proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header REMOTE-HOST $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://ip:8080; proxy_connect_timeout 15s; proxy_send_timeout 600s; proxy_read_timeout 600s; } } 改正配置 # server { listen 443 ssl default_server; server_name test.jinyingweishi.cn; ssl_certificate /usr/local/ssl/cert.pem; ssl_certificate_key /usr/local/ssl/cert.key; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; ssl_prefer_server_ciphers on; location / { add_header Access-Control-Allow-Origin *; add_header Access-Control-Allow-Methods \u0026#39;GET, POST, OPTIONS\u0026#39;; add_header Access-Control-Allow-Headers \u0026#39;DNT,X-Mx-ReqToken,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization\u0026#39;; gzip_static on; root /opt/platform/web/supervise; index index.html index.htm; } location /gaodeX/ { proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header REMOTE-HOST $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://ip:8080/; proxy_connect_timeout 15s; proxy_send_timeout 600s; proxy_read_timeout 600s; } } 改动说明 # 针对于location匹配带不带/的区别 # location /XXX 匹配以 /XX 开头的请求,如果是http://host/xxx可以匹配；但是如果是http://host/xxx/aaa不可以匹配\nlocation /XXX/ 匹配以 /XX/ 开头的请求,则没问题，如果是http://host/xxx 会先重定向到http://host/xxx/再转发\n针对于proxy_pass匹配带不带/的区别 # proxy_pass http://target/XXX/ 请求http://host/XXX/abc 则会转发到http://target/abc\nproxy_pass http://target/XXX 请求http://host/XXX/abc 则会转发到http://target/XXX/abc ","externalUrl":null,"permalink":"/develop/middleware/nginx/nginx%E9%85%8D%E7%BD%AE%E4%BB%A3%E7%90%86%E8%BD%AC%E5%8F%91%E6%B5%81%E9%87%8F/","section":"Develops","summary":"","title":"nginx配置代理转发流量","type":"develop"},{"content":" 业务背景 # giteeAction付费，gitPages也停止了服务，没办法想搞一个国内服务器的独立站只能自己动手了，看了gitee提供了webhook👌那一切就很简单了 部署架构 # 用户做提交代码等操作时，如果满足webhook条件则会发送webhook请求到固定的服务器路由 服务器路由接收到之后就更新git仓库（go 提供服务，真的很方便） 然后生成静态文件部署到nginx webhook设置 # 选择触发事件以及服务路由即可，触发对应事件的时候就会走POST调用\ngo编写web服务 # 真的比java快速且方便很多，需要加密自己写即可\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;os/exec\u0026#34; ) func webhookHandler(w http.ResponseWriter, r *http.Request) { if r.Method == http.MethodPost { // 解析 Webhook 请求的内容 // 这里只是简单的示例，实际情况可能需要更多的处理 body := r.Body defer body.Close() // 你可以根据需要解析请求体中的信息 // 执行 Shell 命令 cmd := exec.Command(\u0026#34;/bin/bash\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;./deploy.sh\u0026#34;) output, err := cmd.CombinedOutput() if err != nil { http.Error(w, \u0026#34;Failed to execute command\u0026#34;, http.StatusInternalServerError) log.Println(\u0026#34;Command execution error:\u0026#34;, err) return } // 输出执行结果 fmt.Fprintf(w, \u0026#34;Command executed successfully: %s\u0026#34;, output) } else { http.Error(w, \u0026#34;Invalid request method\u0026#34;, http.StatusMethodNotAllowed) } } func main() { http.HandleFunc(\u0026#34;/webhook\u0026#34;, webhookHandler) log.Println(\u0026#34;Starting server on :8080\u0026#34;) if err := http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil); err != nil { log.Fatal(\u0026#34;ListenAndServe: \u0026#34;, err) } } 部署脚本 # #!/bin/bash # 定义路径 path=\u0026#34;/opt/webhook/blue-whale/\u0026#34; deployPath=\u0026#34;/opt/www/blueWhale/\u0026#34; gitPath=\u0026#34;git@gitee.com:jzwPro/blue-whale.git\u0026#34;; # 检查文件夹是否存在 if [ ! -d \u0026#34;${path}\u0026#34; ]; then echo \u0026#34;Directory does not exist. Cloning the repository...\u0026#34; # 从 Git 仓库克隆项目 git clone ${gitPath} \u0026#34;${path}\u0026#34; else echo \u0026#34;Directory exists. Pulling the latest changes...\u0026#34; fi cd \u0026#34;${path}\u0026#34; || exit git pull # 生成 Hugo 静态文件 /opt/hugo/hugo # 删除目标目录及其内容（如果存在） rm -rf \u0026#34;${deployPath}\u0026#34; mkdir -p \u0026#34;${deployPath}\u0026#34; # 复制生成的静态文件到目标目录 cp -r ./public/* \u0026#34;${deployPath}\u0026#34; echo \u0026#34;Deployment completed successfully.\u0026#34; ","externalUrl":null,"permalink":"/develop/design/%E5%9F%BA%E4%BA%8Egitee%E7%9A%84webhook%E7%9A%84%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2%E6%96%B9%E6%A1%88/","section":"Develops","summary":"","title":"基于gitee的webhook的自动部署方案","type":"develop"},{"content":" togally/BlueWhale HTML 1 0 ","externalUrl":null,"permalink":"/menu/project/","section":"Menus","summary":"","title":"项目","type":"menu"}]